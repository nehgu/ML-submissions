{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126837, 52)\n",
      "(31709, 51)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_ml as pdml\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "\n",
    "import timeit\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_rows', 6)\n",
    "\n",
    "# train_df = pd.read_csv('data.csv',header=0, index_col=0, nrows=20000)\n",
    "train_df = pd.read_csv('data.csv',header=0, index_col=0)\n",
    "test_df = pd.read_csv('quiz.csv',header=0, index_col=0)\n",
    "print(train_df.shape)\n",
    "# convert to pdml.ModelFrame\n",
    "\n",
    "#train_df = pdml.ModelFrame(train_df,target='label')\n",
    "train_df=train_df.dropna()\n",
    "#test_df = pdml.ModelFrame(test_df)\n",
    "test_df=test_df.dropna()\n",
    "\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# polynomail feature will be added after executing impute function, since \n",
    "# leveraging the filled in mediums should be beneficial.\n",
    "def add_polynomial_feauture(A):\n",
    "    numeric_cols = A.loc[:,['59', '60']]\n",
    "    A['68'] = A['59']*A['60']\n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate new features here ...\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def new_bigram(A):\n",
    "    # column_key = 65 is a bigram of feature 7 and 8\n",
    "    A['65'] = A['7'].map(str) + '-' + A['8']\n",
    "    # column_key = 66 is a bigram of feature 16 and 17\n",
    "    A['66'] = A['16'].map(str) + '-' + A['17']\n",
    "\n",
    "    return A\n",
    "\n",
    "# add bigram here...\n",
    "train_df = new_bigram(train_df)\n",
    "test_df = new_bigram(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '5', '7', '8', '9', '11', '14', '16', '17', '18', '20', '23', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '63', '64', 'label', '65', '66']\n",
      "['2', '5', '7', '8', '9', '11', '14', '16', '17', '18', '20', '23', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '63', '64', 'label', '65', '66']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)    \n",
    "\n",
    "    \n",
    "feature_columns_to_use = ([x for x in train_df.columns])\n",
    "print(feature_columns_to_use)\n",
    "\n",
    "# when adding new features above, the labels won't be at the last column\n",
    "# so I drop it by name\n",
    "\n",
    "feature_columns_to_use = [f for f in feature_columns_to_use if f != 'label']\n",
    "print(feature_columns_to_use)\n",
    "\n",
    "\n",
    "numeric_cols = ['59','60']\n",
    "nonnumeric_columns = feature_columns_to_use[0:46]+feature_columns_to_use[48:]\n",
    "\n",
    "\n",
    "# Join the features from train and test together before imputing missing values,\n",
    "# in case their distribution is slightly different\n",
    "# We'll impute missing values using the median for numeric columns and the most\n",
    "# common value for string columns.\n",
    "big_X = train_df[feature_columns_to_use].append(test_df[feature_columns_to_use])\n",
    "big_X_imputed = DataFrameImputer().fit_transform(big_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To handle categorical features, we need to change\n",
    "# them to columns of integer values.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for feature in nonnumeric_columns:\n",
    "    big_X_imputed[feature] = le.fit_transform(big_X_imputed[feature])\n",
    "    \n",
    "    \n",
    "# remove the test data\n",
    "big_X_imputed_test = big_X_imputed[train_df.shape[0]::]\n",
    "big_X_imputed = big_X_imputed[0:train_df.shape[0]]\n",
    "\n",
    "# feature expansion polynomial\n",
    "big_X_imputed = add_polynomial_feauture(big_X_imputed)\n",
    "big_X_imputed_test = add_polynomial_feauture(big_X_imputed_test)\n",
    "# print(big_X_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the inputs for the model\n",
    "train_X = big_X_imputed.as_matrix()\n",
    "test_X = big_X_imputed_test.as_matrix()\n",
    "train_y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Trained!\n",
      "Time: 86.44309179000265\n",
      "[ 0.94077578  0.94597791  0.94082028]\n",
      "Accuracy: 0.9425 (+/- 0.005)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "\n",
    "# Create and fit an AdaBoosted decision tree\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# bdt = AdaBoostClassifier(forest,\n",
    "#                          algorithm=\"SAMME.R\", \n",
    "#                          n_estimators=200,\n",
    "#                          learning_rate=1)\n",
    "\n",
    "n = train_X.shape[0]\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "# forest = forest.fit(train_X[:int(n*9/10)], train_y[:int(n*9/10)])\n",
    "forest = forest.fit(train_X, train_y)\n",
    "# bdt = bdt.fit(train_X, train_y)\n",
    "# scores = cross_validation.cross_val_score(bdt, train_X, train_y, cv=3)\n",
    "\n",
    "scores = cross_validation.cross_val_score(forest, train_X, train_y, cv=3)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print('Classifier Trained!')\n",
    "print('Time: ' + str(elapsed))\n",
    "\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.4f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Records</h2>\n",
    "<h4>Only Random Forest</h4>\n",
    "\n",
    "** n = 25**<br>\n",
    "[ 0.93912015, 0.94198065, 0.93838403] -- Accuracy: 0.9398 (+/- 0.003)\n",
    "\n",
    "** n =50**<br>\n",
    "[ 0.94157994, 0.94564677, 0.9409622 ] -- Accuracy: 0.9427 (+/- 0.004)\n",
    "\n",
    "** n =80**<br>\n",
    "[ 0.94162725  0.94541025  0.94103316] -- Accuracy: 0.9427 (+/- 0.004)\n",
    "\n",
    "**n = 200** <br>\n",
    "[ 0.94077578, 0.94517373, 0.9409149 ] -- Accuracy: 0.94 (+/- 0.00)\n",
    "\n",
    "**n = 230**<br>\n",
    "[ 0.94139073, 0.94567043, 0.94108047] -- Accuracy: 0.94 (+/- 0.00)\n",
    "\n",
    "**n = 250**<br>\n",
    "[ 0.94127247  0.94609617  0.941317  ] -- Accuracy: 0.94 (+/- 0.00)\n",
    "\n",
    "** n = 300 **<br>\n",
    "[ 0.94139073, 0.9464273, 0.94105681] -- Accuracy: 0.9430 (+/- 0.005)\n",
    "\n",
    "** n = 300 ** <br>\n",
    "[ 0.94117786  0.94604887  0.94115143] -- Accuracy: 0.9428 (+/- 0.005)\n",
    "\n",
    "\n",
    "<h4>Adaboost + Random Forest </h4>\n",
    "\n",
    "** tree = 3, n= 100** <br>\n",
    "[ 0.93219016, 0.93583103, 0.93649179] -- Accuracy: 0.9348 (+/- 0.004)\n",
    "\n",
    "** tree = 3, n=200** <br>\n",
    "[ 0.93261589, 0.93628042, 0.93384266] -- Accuracy: 0.9342 (+/- 0.003)\n",
    "\n",
    "** tree = 3, n=200, learning_rate=1** <br>\n",
    "[ 0.93297067, 0.93590198, 0.9345759 ] -- Accuracy: 0.9345 (+/- 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Work on the test data and generate output file here\n",
    "'''\n",
    "\n",
    "predictions = forest.predict(test_X)\n",
    "\n",
    "\n",
    "indx=[x for x in range(1,31710)]\n",
    "submission = pd.DataFrame({'Id': indx,\n",
    "                           'Prediction': predictions })\n",
    "submission.to_csv(\"submission-rf-1.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
